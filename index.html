<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="google-site-verification" content="CPH3dW_U0N82lUK7MiqGgbH2WCSdaLjgcaXefMjhysI" />
    <title>Jalend Bantupalli</title>

    <meta name="author" content="Jalend Bantupalli">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico"
      type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table
      style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <table
              style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align: center;">
                    Jalend Bantupalli <br>
                    AI Researcher ‚Äì LLMs, Program Synthesis, Embodied Agents
                    </p>
                    <p>I'm a Member of Technical Staff at <a href="https://www.myolab.ai">MyoLab</a>, working on 
                      LLM-based reasoning systems. I completed my Master‚Äôs in Computer Science at 
                      <a href="https://ucsd.edu/">UC San Diego</a>, where I focused on LLM Reasoning and
                       Program Synthesis. Previously, I worked at Google and Microsoft on applied AI systems.

                    </p>
                    <p>
                      At Google, I worked on <a href="https://research.google/teams/network-infrastructure/">Gemini 
                        Networking</a>, and at Microsoft, I contributed to 
                        <a href="https://www.microsoft.com/en-us/dynamics-365/solutions/sales-and-marketing">AI-powered Dynamics 365</a>. 
                        I earned my B.Tech from IIT Kharagpur, where I was advised by Professor Animesh Mukherjee on fairness in NLP, culminating in our paper on decoding demographic bias.
                      </p>
                      <p style="text-align:center">
                        <a href="mailto:jalend.bantupalli@gmail.com">Email</a>
                        &nbsp;/&nbsp;
                        <a href="data/SWE_Jalend (3).pdf">CV</a> &nbsp;/&nbsp;
                        <a
                          href="https://www.linkedin.com/in/jalend-bantupalli-3759a4196/">Linkedin</a>
                        &nbsp;/&nbsp;
                        <a
                          href="https://scholar.google.com/citations?user=B-cMjmgAAAAJ&hl=en">Scholar</a>
                        &nbsp;/&nbsp;
                        <a href="https://x.com/JalendBantupal2">Twitter</a>
                        &nbsp;/&nbsp;
                        <a href="https://github.com/Jalend15/">Github</a>
                      </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                      <a href="images/tmp1.png"><img
                          style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;"
                          alt="profile photo" src="images/tmp1.png"
                          class="hoverZoomLink"></a>
                          <div style="display: flex; justify-content: flex-start; gap: 10px; margin-top: 15px;">
                            <div style="text-align: center;">
                                <img src="images/ucsd.png" alt="UCSD" style="width: 50px; height: 50px;">
                            </div>
                            <div style="text-align: center;">
                                <img src="images/goog.png" alt="Google" style="width: 50px; height: 50px;">
                            </div>
                            <div style="text-align: center;">
                                <img src="images/msr.png" alt="Microsoft" style="width: 50px; height: 50px;">
                            </div>
                            <div style="text-align: center;">
                                <img src="images/IIT_Kharagpur_Logo.svg.png" alt="IIT KGP" style="width: 50px; height: 50px;">
                            </div>
                        </div>
                    </td>
                  </tr>
                </tbody></table>
                <!-- <div style="display: flex; justify-content: space-around; margin-bottom: 20px;">
                  <div style="text-align: center;">
                      <img src="images/ucsd.png" alt="UCSD" style="width: 100px; height: 100px;">
                  </div>
                  <div style="text-align: center;">
                      <img src="images/goog.png" alt="Google" style="width: 100px; height: 100px;">
                  </div>
                  <div style="text-align: center;">
                      <img src="images/msr.png" alt="Microsoft" style="width: 100px; height: 100px;">
                  </div>
                  <div style="text-align: center;">
                    <img src="images/IIT_Kharagpur_Logo.svg.png" alt="IIT KGP" style="width: 100px; height: 100px;">
                </div>
              </div> -->
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
<h2>Research</h2>
<p>
  My research focuses on <strong>Large Language Model (LLM) reasoning</strong>, <strong>program synthesis</strong>, and <strong>multimodal understanding</strong>. I‚Äôm particularly interested in enabling LLMs to perform structured, step-by-step reasoning in complex environments where inputs span across natural language, formal representations (e.g., code, logic), and physical modalities such as motion or visual context. This includes developing models that can solve problems by abstracting patterns, composing subroutines, and leveraging prior examples ‚Äî rather than relying on brute-force memorization. I aim to design systems that are not only general-purpose and data-efficient, but also interpretable and aligned with human-like reasoning capabilities.
</p>

<p>
  At <a href="https://www.myolab.ai" target="_blank">MyoLab</a>, I work on developing LLM-based agents that interact with embodied data (e.g., body movements, sensor inputs) to solve complex reasoning tasks. My broader goal is to create learning frameworks that combine LLMs with <strong>reinforcement learning</strong> and <strong>vision</strong> to enable grounded, goal-directed intelligence.
</p>

<p>
  üìù I recently co-authored <a href="https://arxiv.org/abs/2503.07018" target="_blank">ImplexConv</a>, a large-scale dataset and retrieval framework for implicit reasoning in personalized multi-session conversations. Our proposed method, <strong>TaciTree</strong>, introduces hierarchical multi-level summarization to support efficient long-context reasoning. <em>(Preprint on <a href="https://arxiv.org/abs/2503.07018">arXiv</a>)</em>
</p>

                        <!-- Some
                        projects are <span class="highlight">highlighted</span>. -->
                      </p>
<div style="background: #f9f9f9; border-left: 4px solid #007acc; padding: 12px 16px; margin-top: 20px;">
  <h3 style="margin: 0 0 10px 0;">üî¨ What I'm Working On</h3>
  <ul style="margin: 0; padding-left: 20px; font-size: 14px;">
    <li>üß† Building multimodal LLM agents at <a href="https://www.myolab.ai" target="_blank">MyoLab</a>.</li>
<li>üöÄ Launched a <a href="https://demo.myolab.ai/demo">live demo</a> with motion-text retrieval.</li>
<li>üì¢ Shared publicly on <a href="https://www.linkedin.com/posts/myolab-ai_myo-activity-7346148284551323649-3v68?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC4QkwkB-q6rXXl36VxElR2NLDni0RQP48o">LinkedIn</a>.</li>
    <li>üìù Co-authored <a href="https://arxiv.org/abs/2503.07018" target="_blank">ImplexConv</a>, a new dataset and framework for implicit reasoning in personalized multi-session dialogue. <em>(Preprint available)</em></li>

  </ul>
</div>
                <h2>üìÑ Publications</h2>
                    </td>
                  </tr>
                </tbody></table>
                <table
                <tr onmouseout="guandao_stop()"
                onmouseover="guandao_start()">
                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <div class="one" style="text-align: center;">
                        <div class="two" id='implex_image'>
                          <img src='images/implex.png' width="100%">
                        </div>
                      </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2503.07018">
                        <span class="papertitle">Toward Multi-Session Personalized Conversation: A Large-Scale Dataset and Hierarchical Tree Framework for Implicit Reasoning</span>
                      </a>
                      <br>
                      Xintong Li, <strong>Jalend Bantupalli</strong>, Ria Dharmani, Yuwei Zhang, Jingbo Shang
                      <br>
                      <em>arXiv Preprint</em>, 2025
                      <br>
                      <a href="https://arxiv.org/abs/2503.07018">arXiv</a>
                      <p></p>
                      <p>
                        Introduced <strong>ImplexConv</strong>, a dataset of 2,500 multi-session conversations and proposed <strong>TaciTree</strong>, a hierarchical tree-based retrieval framework for implicit reasoning in personalized dialogue. Enables scalable long-context modeling with LLMs.
                      </p>
                    </td>
                  </tr>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one" style="text-align: center;">
                      <div class="two" id='ever_image'>
                        <img src='images/decode.png' width="100%">
                      </div>
                    </div>
                    <script type="text/javascript">
                    </script>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://arxiv.org/abs/2209.03089">
                      <span class="papertitle">Decoding Demographic un-fairness
                        from Indian Names
                      </span>
                    </a>
                    <br>
                    Vahini Medidoddi,
                    <strong>Jalend Bantupalli</strong>,
                    Souvic Chakraborty,
                    <a
                      href="https://cse.iitkgp.ac.in/~animeshm/">Animesh
                      Mukherjee</a>,
                    <br>
                    <em>Soc Info</em> 2022
                    <br>
                    <a href="https://github.com/vahini01/IndianDemographics">code</a>
                    /
                    <a href="https://arxiv.org/abs/2209.03089">arXiv</a>
                    <p></p>
                    <p>
                      Introduced large-scale datasets of Indian names and
                      trained transformer models to achieve state-of-the-art
                      performance in gender and caste prediction.

                    </p>
                  </td>
                </tr>
                </table>
                   <h2>üìÑ Contributions</h2>
                <table>

                <tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one" style="text-align: center;">
      <div class="two" id='for_image'>
        <img src='images/for.png' width="100%">
      </div>
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://arxiv.org/pdf/2406.05673">
      <span class="papertitle">Flow of Reasoning: Training LLMs for Divergent Problem Solving with Minimal Examples</span>
    </a>
    <em>arXiv Preprint</em>, 2024
    <br>
    <a href="https://yu-fangxu.github.io/FoR.github.io/">project page</a> /
    <a href="https://arxiv.org/pdf/2406.05673">arXiv</a>
    <p></p>
    <p>
      Achieved <strong>state-of-the-art 50.37% accuracy</strong> on the 1D ARC synthesis task. Developed training strategies and evaluation protocols for generalization from few-shot examples.
    </p>
  </td>
</tr>
</table>
               <table
                  style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                      <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                          Reference to <a
                            href="https://github.com/jonbarron/jonbarron_website">source
                            code</a>.
                        </p>
                      </td>
                    </tr>
                  </tbody></table>
              </td>
            </tr>
          </table>
        </body>
      </html>

      