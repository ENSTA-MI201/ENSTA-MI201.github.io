<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Dohyeok Lee</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Dohyeok Lee
                </p>
                <p>
                  I'm a first year Ph.D. student at <a href="https://cml.snu.ac.kr/">Cognitive Machine Learning Laboratory</a>, advised by Prof. Jungwoo Lee,
                  in <a href="https://ece.snu.ac.kr/en">Department of Electrical and Computer Engineering</a> at <a href="https://en.snu.ac.kr/index.html/">Seoul National University (SNU)</a>. 
                  Previously, I received my M.S. in ECE from SNU in 2024 and B.S. in <a href="https://ee.kaist.ac.kr/en/">EE</a> from <a href="https://www.kaist.ac.kr/en/">KAIST</a> in 2020.
                </p>
                <p>
                  <strong>Research Keywords</strong>: Robot Learning, Robotics, Learning from Demonstration (LfD), Reinforcement Learning (RL).
                </p>

                <p style="text-align:center">
                  <a href="mailto:dohyeoklee.kr@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_dhlee.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=RcFFkMYAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/dohyeoklee/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/dohyeoklee/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/dohyeoklee.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/dohyeoklee.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
          <h2>Research Vision</h2>
          <p class="research-question">
            <strong>How can we leverage physics understanding to make robot learning truly generalizable?</strong>
          </p>
          <p>
            My research focuses on empowering robots with physical understanding to achieve robust generalization across diverse manipulation scenarios
             â€” when agents truly understand the physics and affordances of their environment, they can adapt to novel scenarios beyond their training distribution. 
             I develop algorithms that leverage spatiotemporal dynamics, combining novel view synthesis and dynamics prediction to enable robots to make informed decisions on unseen data.
             My vision is to create robotic systems that autonomously discover and apply physical principles to solve any manipulation task, 
             achieving human-level adaptability in unstructured environments.
            </p>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/spqr_concept.jpg" alt="PontTuset" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2401.03137/" id="MCG_journal">
                  <span class="papertitle">SPQR: Controlling Q-ensemble Independence with Spiked Random Model for Reinforcement Learning</span>
                </a>
                <br>
                <strong>Dohyeok Lee</strong>, <a href="https://hansungy.github.io/">Seungyub Han</a>, Taehyun Cho, Jungwoo Lee
                <br>
                <em>NeurIPS</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2401.03137/">arXiv</a> /
                <a href="https://github.com/dohyeoklee/SPQR">code</a>
                <p></p>
                <p>
                  We proposed SPQR, the first theoretically-grounded independence regularization for ensemble Q-learning based on random matrix theory. 
                  Our approach demonstrates significant improvements in reducing overestimation bias while achieving better computational efficiency in ensemble Q-learning.
                </p>
              </td>
            </tr>
        
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/arte.png" alt="PontTuset" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                  <span class="papertitle">ARTificial Expressions: Human-Robot Interactive Drawing</span>
                <br>
                <a href="https://yejin-kim.com/contact">Yejin Kim</a>, <strong>Dohyeok Lee</strong>
                <br>
                <em>CVPR Demo</em>, 2023 &nbsp <font color="red"><strong>(Best Demo)</strong></font>
                <br>
                <a href="https://github.com/ykim104/ARTE">code</a>
                <p></p>
                <p>
                  We created ARTE, an interactive drawing system enabling collaboration between humans and robots. 
                  The system features a CLIP-based reward mechanism for real-time drawing state assessment and a reinforcement learning policy trained on diverse datasets using brush stroke simulation.
                </p>
              </td>
            </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/dyn_concept figure_1.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://embodied-ai.org/cvpr2025/" id="MCG_journal">
          <span class="papertitle">Dynamics-Aligned Flow Matching Policy for Robot Learning</span>
        </a>
        <br>
        <strong>Dohyeok Lee</strong>, Jung Min Lee, Munkyung Kim, Seokhun Ju, Seungyub Han, Jin Woo Koo, Jungwoo Lee
        <br>
        <em>CVPR Embodied AI Workshop</em>, 2025
        <br>
        <a href="data/dafmp_camera_ready.pdf">paper</a>
        <p></p>
        <p>
          We proposed Dynamics-Aligned Flow Matching Policy to address generalization to out-of-distribution scenarios by integrating random trajectory data (zero annotation cost) with expert demonstrations using dynamics model. 
          Our iterative flow generation enables dynamics and policy models to mutually correct each other during training, combining the robustness of dynamics model with the flexibility of learning.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/vi_figure.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://embodied-ai.org/cvpr2025/" id="MCG_journal">
          <span class="papertitle">View-Imagination: Enhancing Visuomotor Control with Adaptive View Synthesis</span>
        </a>
        <br>
        <strong>Dohyeok Lee</strong>, Munkyung Kim, Jung Min Lee, Seungyub Han, Jungwoo Lee
        <br>
        <em>CVPR Embodied AI Workshop</em>, 2025
        <br>
        <a href="data/vi_camera_ready.pdf">paper</a>
        <p></p>
        <p>
          We proposed View-Imagination, a novel framework that dynamically selects optimal camera viewpoints for robotic manipulation using adaptive view synthesis. 
          Based on our key insight that the most informative viewpoint is scene-dependent, View-Imagination trains a learnable viewpoint policy enabling robots to actively resolve visual ambiguities like occlusions.
        </p>
      </td>
    </tr>

    <tr onmouseout="furuta_stop()" onmouseover="furuta_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='furuta_image'><img src='images/furuta.gif' width="160" height="160"></div>
          <img src='images/furuta.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function furuta_start() {
            document.getElementById('furuta_image').style.opacity = "1";
          }
        
          function furuta_stop() {
            document.getElementById('furuta_image').style.opacity = "0";
          }
          furuta_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Control of Furuta Pendulum with Reinforcement Learning</span>
        <br>
        <strong>Dohyeok Lee</strong>, Usama Mohammad, Dong Eui Chang
        <br>
        <em>ICCAS</em>, 2019
        <br>
        <a href="https://www.youtube.com/watch?v=a6W6u8iMDU8&ab_channel=ControlLabKAIST">video</a>
        <p></p>
        <p>
          Implemented a robust control system for the Furuta pendulum combining swing-up and balancing tasks using DDPG and PPO algorithms, with sim2real transfer and in-the-wild training.
        </p>
      </td>
    </tr> 
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:16px;width:100%;vertical-align:middle">
    <h2>Work Experience</h2>
    <p>
      Prior to my PhD, I gained hands-on robotics experience at two startups, building complete robotic systems from hardware to deployment. 
      This practical background informs my current research on making learning algorithms work reliably in real-world settings.
    </p>
  </td>
</tr>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:16px;width:80%;vertical-align:middle">
      <span class="papertitle">Robotics Engineer</span>
    <br>
    <a href="https://diveintothehive.com/">D.Hive</a> (start-up), Daejeon, Korea
    <br>
    2020.10 - 2021.04
    <br>
    <p>
      <ul>
        <li>Built autonomous outdoor delivery robot from scratch, integrating LiDAR-camera fusion for robust navigation in urban environments</li>
        <li>Led 10-engineer team across hardware/software, achieving successful deployment in real-world delivery scenarios</li>
      </ul>
    </p>
    </td>
  </tr>
  
  <tr>
    <td style="padding:16px;width:80%;vertical-align:middle">
      <span class="papertitle">Robotics Engineer Intern</span>
    <br>
    <a href="https://coops.bot/">Crazing Lab</a> (start-up), Pangyo, Korea
    <br>
    2019.06 - 2019.08
    <br>
    <p>
      <ul>
        <li>Built autonomous filming robot: hardware(frame,battery system), BLDC motor control system, and UART communication system</li>
        <li>Implemented ROS system for motor control, IMU, LiDAR, and depth camera data processing</li>
      </ul>
    </p>
    </td>
  </tr>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:16px;width:100%;vertical-align:middle">
    <h2>Open Source Contribution</h2>
  </td>
</tr>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/impala.png" alt="PontTuset" width="160" style="border-style: none">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">IMPALA</span>
      <br>
      Open Source Contribution, 2024
      <br>
      <a href="https://github.com/dohyeoklee/IMPALA-distributed-RL">code</a>
      <p></p>
      <p>Implemented <a href="https://arxiv.org/abs/1802.01561">IMPALA</a>(Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures) in distributed system with ray, redis, and UDP</p>
    </td>
  </tr>

  <tr onmouseout="n_ctrl_stop()" onmouseover="n_ctrl_start()">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='nctrl_image'><img src='images/nonlinear_ctrl.gif' width="160" height="160"></div>
        <img src='images/nonlinear_ctrl.png' width="160" height="160">
      </div>
      <script type="text/javascript">
        function n_ctrl_start() {
          document.getElementById('nctrl_image').style.opacity = "1";
        }
      
        function n_ctrl_stop() {
          document.getElementById('nctrl_image').style.opacity = "0";
        }
        n_ctrl_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">Nonlinear Controller (â˜…20)</span>
      <br>
      Open Source Contribution, 2021
      <br>
      <a href="https://github.com/dohyeoklee/Non-linear-control-simulator">code</a>
      <p></p>
      <p>Implemented nonlinear control (robust, adaptive, sliding mode) algorithms on two-arm manipulator simulator</p>
    </td>
  </tr>

  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/EKF.png" alt="PontTuset" width="160" height="160" style="border-style: none">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">EKF (â˜…14)</span>
      <br>
      Open Source Contribution, 2021
      <br>
      <a href="https://github.com/dohyeoklee/EKF-kitti-GPS-IMU">code</a>
      <p></p>
      <p>Implemented EKF(Extended Kalman Filter) for sensor fusion of GPS and IMU data with Kitti dataset
    </td>
  </tr>

  <tr onmouseout="rrt_stop()" onmouseover="rrt_start()">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='rrt_image'><img src='images/rrt.gif' width="160" height="160"></div>
        <img src='images/rrt.jpeg' width="160" height="160">
      </div>
      <script type="text/javascript">
        function rrt_start() {
          document.getElementById('rrt_image').style.opacity = "1";
        }
      
        function rrt_stop() {
          document.getElementById('rrt_image').style.opacity = "0";
        }
        rrt_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">RRT</span>
      <br>
      Open Source Contribution, 2021
      <br>
      <a href="https://github.com/dohyeoklee/RRT-python">code</a>
      <p></p>
      <p>Implemented RRT(Rapid Random Tree) algorithms
    </td>
  </tr>     


  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:16px;width:100%;vertical-align:middle">
      <h2>Robotics Project</h2>
    </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/humanoid.jpg" alt="PontTuset" width="160" height="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Mobile Humanoid</span>
        <br>
        Course Project at SNU (Actuation and Sensing Mechanisms for Robots), 2024
        <br>
        Collaborator: <strong>Dohyeok Lee</strong>, and 23 students
        <br>
        <p></p>
        <p>Developed wheel-based humanoid for navigation and object manipulation</p>
      </td>
    </tr>

    <tr onmouseout="spot_stop()" onmouseover="spot_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='spot_image'><img src='images/spot.gif' width="160" height="160"></div>
          <img src='images/spot.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function spot_start() {
            document.getElementById('spot_image').style.opacity = "1";
          }
        
          function spot_stop() {
            document.getElementById('spot_image').style.opacity = "0";
          }
          spot_stop()
        </script>
      </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">Robot-AR system</span>
      <br>
      In collaboration with Zer01ne(Hyundai Motor Company), 2021
      <br>
      Collaborator: <a href="https://minyoung.works/information">Minyoung Kim</a>, <a href="https://yejin-kim.com/contact">Yejin Kim</a>, <strong>Dohyeok Lee</strong>, Junyoung Kim, Sunho Chang
      <br>
      <a href="https://www.youtube.com/watch?v=ux7y3rQ4NdQ">video1</a> /
      <a href="https://vimeo.com/643065295">video2</a>
      <p></p>
      <p>Developed Unity-ROS pipeline for AR visualization of Boston Dynamics Spot, enabling intuitive robot control system</p>
    </td>
  </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/vender.png" alt="PontTuset" width="160" height="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Vender</span>
        <br>
        In collaboration with Art Center Nabi, 2020
        <br>
        Collaborator: <a href="https://minyoung.works/information">Minyoung Kim</a>, <strong>Dohyeok Lee</strong>, <a href="https://seoseong.uk/">Seonguk Seo</a>, <a href="https://itsc.kr/">Taewon Kang</a>, Dahye Lee, Daeun Kim
        <br>
        <a href="https://www.youtube.com/watch?v=b-Zn6jU1vfc">video</a>
        <p></p>
        <p>Created A.I media artwork with A.I based emotion recognition and autonomous vending machine system</p>
      </td>
    </tr>

    <tr onmouseout="auto_stop()" onmouseover="auto_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='auto_image'><img src='images/auto.gif' width="160" height="160"></div>
          <img src='images/autonomous_robot.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function auto_start() {
            document.getElementById('auto_image').style.opacity = "1";
          }
        
          function auto_stop() {
            document.getElementById('auto_image').style.opacity = "0";
          }
          auto_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">Autonomous Mobile Robot</span>
          <br>
          In collaboration with robotics club MR, KAIST, 2018
          <br>
          Collaborator: <strong>Dohyeok Lee</strong>, Inyub Kim, Yongmin Lee, Dokyun Lee
          <br>
          <a href="https://www.youtube.com/watch?v=HwjY57Dp25U">video</a>
          <br>
          <p></p>
          <p>
            Developed autonomous mobile robot with YOLO, Tmap API, GPS and compass sensor, etc.
          </p>
        </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/teleop_dex_manipulator.jpg" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://mr.kaist.ac.kr/projects/70" id="MCG_journal">
          <span class="papertitle">Hand-shape Manipulator with Teleoperation</span>
        </a>
        <br>
        In collaboration with robotics club MR, KAIST, 2017
        <br>
        Collaborator: <strong>Dohyeok Lee</strong>, Jaemin Cho, Jinsub Lee, Kiheon Sung
        <br>
        <p></p>
        <p>Developed hand-shape manipulator and glove-shape interface for teleoperation</p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/marker_robot_image_1.png" alt="PontTuset" width="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://mr.kaist.ac.kr/projects/55" id="MCG_journal">
          <span class="papertitle">Marker-based Mobile Robot</span>
        </a>
        <br>
        In collaboration with robotics club MR, KAIST, 2016
        <br>
        Collaborator: Duckyu Choi, <a href="https://wjuni.com/">Hwijoon Lim</a>, <strong>Dohyeok Lee</strong>
        <br>
        <p></p>
        <p>Developed mobile robot for marker-based localization and mapping</p>
      </td>
    </tr>
	

	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:16px;width:100%;vertical-align:middle">
      <h2>Other Research Project</h2>
    </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
   


    <tr onmouseout="iso_stop()" onmouseover="iso_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='iso_image'><img src='images/iso.gif' width="160" height="160"></div>
          <img src='images/iso.png' width="160" height="160">
        </div>
        <script type="text/javascript">
          function iso_start() {
            document.getElementById('iso_image').style.opacity = "1";
          }
        
          function iso_stop() {
            document.getElementById('iso_image').style.opacity = "0";
          }
          iso_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Minimum distortion embedding for RL</span>
        <br>
        Taehyun Cho, <strong>Dohyeok Lee</strong>, Jungwoo Lee
        <br>
        <em>KICS Winter Conference</em>, 2023
        <br>
        <a href="data/min_distorsion_RL.pdf">preprint</a> / 
        <a href="https://github.com/dohyeoklee/Manifold-Isometric-Regularization-RL">code</a>
        <p></p>
        <p>
          Proposed isometric regularization for RL to minimize distortion of latent space embedding
        </p>
      </td>
    </tr>

	  <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/sbe_dqn.png" alt="PontTuset" width="160" height="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Separated batch ensemble DQN</span>
        <br>
        <strong>Dohyeok Lee</strong>, Jungwoo Lee
        <br>
        <em>KICS Winter Conference</em>, 2023
        <br>
        <a href="https://github.com/dohyeoklee/Sperated-Batch-Ensemble-DQN">code</a>
        <p></p>
        <p>
          Proposed separated batch ensemble DQN for diversification of ensemble using separated batch for Bellman Q-target
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/surf_decomp.png" alt="PontTuset" width="160" height="160" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Genetic Algorithm for Surface Decomposition</span>
        <br>
        Research Project, 2022
        <br>
        <a href="https://github.com/dohyeoklee/surface-decomposition-genetic-algorithm">code</a>
        <p></p>
        <p>Implemented genetic algorithm for earth surface decomposition with arbitrary basis function</p>
      </td>
    </tr>


    <tr onmouseout="drone_stop()" onmouseover="drone_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='drone_image'><img src='images/Drone_RL_13x13_move.gif' width="160" height="160"></div>
          <img src='images/Drone_RL_13x13_move-0000.jpg' width="160" height="160">
        </div>
        <script type="text/javascript">
          function drone_start() {
            document.getElementById('drone_image').style.opacity = "1";
          }
        
          function drone_stop() {
            document.getElementById('drone_image').style.opacity = "0";
          }
          drone_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Simulator and Reinforcement Learning Algorithms for Surveillance/Reconnaissance</span>
        <br>
        Changsik Lee, <strong>Dohyeok Lee</strong>, Dong Eui Chang
        <br>
        <em>KIMST Conference</em>, 2020
        <br>
        <p></p>
        <p>Developed simulation environment for surveillance/reconnaissance and reinforcement learning algorithms for surveillance agent</p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/3d_pose.png" alt="PontTuset" width="160" height="100" style="border-style: none">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">3D Box Fitting</span>
        <br>
        In collaboration with RCV KAIST, 2018
        <br>
        Collaborator: <strong>Dohyeok Lee</strong>, Jaekook Hyun
        <br>
        <p></p>
        <p>Developed 3D box fitting algorithm for given point cloud data, collaboration with Hubo lab</p>
      </td>
    </tr>
       

        
     <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:16px;width:80%;vertical-align:middle">
              Service: Reviewer for NeurIPS 2025, CoRL Workshop 2024, ITW 2024
            </td>	
           
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  template adapted from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
